---
layout: post
title: "The Price of Admission"
tags:
- academia
- politics
---

I want to try to knit together two things that are discouraging me about the way we talk about the relationship between academia and the world at large, in particular, between academics whose work levies critique against technologized systems and the industries that architect those systems in the first place. 

First, a lengthy passage from N. Katherine Hayles' recent book *Unthought: The Power of the Cognitive Nonconscious*, specifically from a chapter about high-frequency trading, which ends: 

> To be taken seriously in this endeavor, humanists will need to learn the vocabulary, mechanisms, and histories of finance capital. While Stiegler’s work has much to offer in this regard, it is couched in terminology that an economist would find completely opaque; Hansen’s work, although more lucid, is also dense with argumentation and references that the finance community would likely find diffcult to negotiate. The work of building bridges between finance capital and the rich critical and philosophical traditions of the humanities requires that humanists learn to write and speak in ways legible to the finance community, for only so can there be a successful transmission of ideas across these fields. The price to gain admission to discussions with economists, business school professors, traders, politicians, and other influential actors is steep, but the potential contributions humanists can make more than justify the investment. If there is no way out of the global financial system, then the way forward may require going more deeply into it. “Critical Studies in Finance Capital” should be a project in which humanists claim their stakes and make their arguments, transforming it even as we are also transformed by it. (176–77)

And second, a tweet from mathematician Cathy O'Neil, in response to backlash from academics to [her op-ed in the *New York Times*](https://www.nytimes.com/2017/11/14/opinion/academia-tech-algorithms.html) calling for academic analysis of the role of algorithms in everyday life: 

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr">Guys, we&#39;re in a bubble here on Twitter. Talk to insurance industry execs, see if they&#39;re talking about this. They&#39;re not.</p>&mdash; Cathy O&#39;Neil (@mathbabedotorg) <a href="https://twitter.com/mathbabedotorg/status/930502071429877760?ref_src=twsrc%5Etfw">November 14, 2017</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

I have tremendous respect for both Hayles and O'Neil, whose work has been influential to my thinking about a range of issues at the intersection of technology and the humanities. They are both careful and nuanced thinkers who fundamentally support the role of the humanities in changing our world for the better. Still, I am dismayed at the tacit argument running underneath these claims: that the language of the academic is incommensurate with making a worldly impact, that we humanists speak in a key that no one else can hear, or at least wants to listen to, and therefore we must modulate the tenor and tactics of our analysis such that we can make a real impact on financiers and insurance executives—synecdoche for the power brokers of capitalism in our time. Bernard Stiegler and Mark Hansen's work, so argues Hayles, is fundamentally *right*: the problem is the package, its "terminology," "argumentation," and "references."

Now, O'Neil's op-ed is getting rigorously dismantled on Twitter as I write this: its claim that "there is essentially no distinct field of academic study that takes seriously the responsibility of understanding and critiquing the role of technology—and specifically, the algorithms that are responsible for so many decisions—in our lives" is laughable and honestly shocking to me when I read it this morning. Even if we nuance her claim to say that she's talking about "academic institutes" we can still point to [Data & Society](https://datasociety.net/), the [Berkman Klein Center](https://cyber.harvard.edu/), or [AINow](https://ainowinstitute.org/) as examples of precisely that sort of thing—examples that [the tweet previous to the O'Neil's embedded above indeed lists](https://twitter.com/geomblog/status/930451632277528578). 

That O'Neil responded to a list of these institutes with the claim that DH, STS, and information studies folks on Twitter are in a bubble is then interesting, given that even a cursory observation of how power functions in American society today would suggest that the bubble is *precisely the other way around*: that insurance executives are walled up, refusing to listen to the academics whose carefully researched and argued work seeks to critique, destabilize, and fundamentally reshape the systems by which they generate ill-gotten profits. Her claim presumes that [major technology companies are not actively influencing research](https://www.theguardian.com/technology/2017/jul/13/google-millions-academic-research-influence-opinion) in favor of their business interests, that they are either unaware or dismissive of academic research. Undoubtedly they are. But the question is: why? Is it because we academics do not speak the right language? Or is it because their paychecks depend on not listening to us, on not making the interventions that we call for?

Moreover, I have to ask how the proliferation of these sorts of institutional configurations will meaningfully intercede, if they are not meaningfully interceding already. Perhaps the problem really is, as O'Neil suggests, simply one of volume. But if those in power aren't listening to Harvard, the institution that undoubtedly helped them to power in the first place, I struggle to buy this claim. 

But we can return to Hayles' argument concerning language. Perhaps academics are not speaking the proper language of finance, or insurance, or algorithms: we are then not properly understood. I can't help but push back against this argument, however, given that I struggle to imagine how the fundamental message of much DH and STS work on finance capital and algorithms, for example, is anything other than "this is a gross misuse of technical capacity and political power, and we need to nuance or even stop this work altogether." How do you reframe and nuance that fundamental argument? When Zeynep Tufekci argues that [adtech delimits our ability to practice democracy](https://www.ted.com/talks/zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads), it's hard to imagine how to change the language or pitch of this argument to any other end than "Facebook needs a new business model, STAT." When Safiya Noble argues that machine learning in search engines [implicitly reinforces racist imaginaries](https://nyupress.org/books/9781479837243/), it's hard to imagine how Google can continue to make profits in its current form. The best work in digital and science and technology studies uses the language of the humanities to specifically call for *remaking* the world as we know it. That language is integral to this work of remaking, and to say that we can cede rhetorical ground to finance, for example, bespeaks less a desire to change industry than to have a seat at the table with it. 

The best, most revolutionary work against power is marginalized precisely *because* it troubles the powerful. If "the price to gain admission" is the soul of our work—our critique—then I do not know if admission is worth the price.